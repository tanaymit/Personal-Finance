# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from __future__ import annotations

from typing import Union, Iterable, Optional
from typing_extensions import Literal, Required, TypeAlias, TypedDict

from .audio_param import AudioParam
from .chat_completion_content_part_text_param import ChatCompletionContentPartTextParam
from .chat_completion_message_tool_call_param import ChatCompletionMessageToolCallParam
from .chat_completion_content_part_refusal_param import ChatCompletionContentPartRefusalParam
from .chat_completion_message_custom_tool_call_param import ChatCompletionMessageCustomToolCallParam

__all__ = [
    "ChatCompletionAssistantMessageParam",
    "ContentChatCompletionRequestAssistantMessageContentArray",
    "FunctionCall",
    "ToolCall",
]

ContentChatCompletionRequestAssistantMessageContentArray: TypeAlias = Union[
    ChatCompletionContentPartTextParam, ChatCompletionContentPartRefusalParam
]


class FunctionCall(TypedDict, total=False):
    """Deprecated and replaced by `tool_calls`.

    The name and arguments of a function that should be called, as generated by the model.

    Fields:
    - arguments (required): str
    - name (required): str
    """

    arguments: Required[str]
    """
    The arguments to call the function with, as generated by the model in JSON
    format. Note that the model does not always generate valid JSON, and may
    hallucinate parameters not defined by your function schema. Validate the
    arguments in your code before calling your function.
    """

    name: Required[str]
    """The name of the function to call."""


ToolCall: TypeAlias = Union[ChatCompletionMessageToolCallParam, ChatCompletionMessageCustomToolCallParam]


class ChatCompletionAssistantMessageParam(TypedDict, total=False):
    """Messages sent by the model in response to user messages.

    Fields:
    - content (optional): str | Annotated[list[ChatCompletionRequestAssistantMessageContentPart], MinLen(1), ArrayTitle("ChatCompletionRequestAssistantMessageContentArray")] | None
    - refusal (optional): str | None
    - role (required): Literal["assistant"]
    - name (optional): str
    - audio (optional): Audio | None
    - tool_calls (optional): ChatCompletionMessageToolCalls
    - function_call (optional): FunctionCall | None
    """

    role: Required[Literal["assistant"]]
    """The role of the messages author, in this case `assistant`."""

    audio: Optional[AudioParam]
    """
    Data about a previous audio response from the model.
    [Learn more](https://platform.openai.com/docs/guides/audio).

    Fields:

    - id (required): str
    """

    content: Union[str, Iterable[ContentChatCompletionRequestAssistantMessageContentArray], None]
    """The contents of the assistant message.

    Required unless `tool_calls` or `function_call` is specified.
    """

    function_call: Optional[FunctionCall]
    """Deprecated and replaced by `tool_calls`.

    The name and arguments of a function that should be called, as generated by the
    model.

    Fields:

    - arguments (required): str
    - name (required): str
    """

    name: str
    """An optional name for the participant.

    Provides the model information to differentiate between participants of the same
    role.
    """

    refusal: Optional[str]
    """The refusal message by the assistant."""

    tool_calls: Iterable[ToolCall]
    """The tool calls generated by the model, such as function calls."""
